#!/usr/bin/env python
# coding: utf-8

# ## Проект
# Представьте, что вы работаете в компании, которая разрабатывает мобильные игры. К вам пришел менеджер с рядом задач по исследованию нескольких аспектов мобильного приложения:
# 
# В первую очередь, его интересует показатель retention. Напишите функцию для его подсчета.
# Помимо этого, в компании провели A/B тестирование наборов акционных предложений. На основе имеющихся данных определите, какой набор можно считать лучшим и на основе каких метрик стоит принять правильное решение.
# Предложите метрики для оценки результатов последнего прошедшего тематического события в игре.
#  
# ### Задание 1
# Retention – один из самых важных показателей в компании. Ваша задача – написать функцию, которая будет считать retention игроков (по дням от даты регистрации игрока). Данные лежат в папке shared и имеют следующую структуру:

# In[1]:


import pandas as pd
import datetime 
import matplotlib.pyplot as plt
import seaborn as sns


# In[3]:


# Подготовка баз для анализа (присвоение переменным ссылки, обработка таблиц)
reg_df = pd.read_csv('problem1-reg_data.csv', sep=(';'))
auth_df = pd.read_csv('problem1-auth_data.csv', sep=(';'))


# In[ ]:


# Выведем загруженные данные
reg_df.head()


# In[ ]:


reg_df.dtypes


# In[ ]:


auth_df.head()


# In[ ]:


# Приступаем к основному блоку: расчет показателя Retention (написание функции)
def retention(regd, authd):
    
    # Делаем преобразование UNIX в формат даты для дальнейшего анализа
    regd['reg_date'] = pd.to_datetime(reg_df['reg_ts'], unit='s').dt.date
    authd['auth_date'] = pd.to_datetime(auth_df['auth_ts'], unit='s').dt.date
    
    # Определяем период для проверки работы функции (период можно задать любой в рамках данных таблицы, в тек. версии июль'19)
    regd = regd[(regd['reg_date'] >= datetime.date(2019,7,1))]
    authd = authd[(authd['auth_date'] <= datetime.date(2019,7,31))]

    # Объединяем данные по регистрации и времени захода игроков для получения единой таблицы
    total_data  = pd.merge(authd, regd, on='uid')
    
    # Вычисляем разницу в днях от времени регистрации до времени захода игроков
    total_data['dd'] = (total_data['auth_date'] - total_data['reg_date']).dt.days + 1
    
    # Формируем когорты игроков
    cohorts_df = total_data.groupby(['reg_date', 'dd'])['uid'].nunique().reset_index() 
    cohorts = cohorts_df.pivot(index='reg_date', columns='dd', values='uid')
    base = cohorts[1] 
    retention = cohorts.divide(base, axis=0).round(3)
    
    # Визуализация показателя
    plt.figure(figsize=(18,14))
    plt.title('Retention')
    ax = sns.heatmap(data=retention, annot=True, fmt='.0%', vmin=0.0, vmax=0.15, cmap='YlGnBu')
    ax.set_yticklabels(retention.index)
    fig=ax.get_figure()
    plt.show()
    
    return{"retention_data": retention}  


# In[ ]:


retention_data = retention(reg_df, auth_df) 


# Расчет Retention произведен на основании данных с использованием детализации по дням в рамках полного месяца.
# Возвращаемость игроков на анализируемую платформу/игру низкая (может свидельствовать как о проблемах работы самой игры, так и отсутсвия интереса пользователей к игре).
# 
# В зависимости от цели анализа: отклик игроков на промо, рекламу и др.активности или же выявление сезональности, расчет может производится в разных агрегациях периодов.

# ## Задание 2

# Имеются результаты A/B теста, в котором двум группам пользователей предлагались различные наборы акционных предложений. Известно, что ARPU в тестовой группе выше на 5%, чем в контрольной. При этом в контрольной группе 1928 игроков из 202103 оказались платящими, а в тестовой – 1805 из 202667.
# 
# Какой набор предложений можно считать лучшим? Какие метрики стоит проанализировать для принятия правильного решения и как?

# In[52]:


import pandas as pd
import numpy as np
import scipy.stats as stats
from scipy.stats import norm, mannwhitneyu
import seaborn as sns
import matplotlib.pyplot as plt
from tqdm.auto import tqdm
plt.style.use('ggplot')


# In[53]:


df= pd.read_csv('/mnt/HC_Volume_18315164/home-jupyter/jupyter-k-guschenko-22/Final/Проект_1_Задание_2.csv', sep=(';'))


# In[54]:


# Выведем загруженные данные


# In[55]:


df.head()


# In[56]:


df.shape


# In[57]:


df.nunique()


# In[58]:


# Для дальнейшего удобства сделаем присвоение ирокам статуса: 1 = payment (платежес-ный), 0 - no payment (не платежес-ный)


# In[59]:


df['pay_status'] = np.where(df['revenue'] > 0, 1, 0)


# In[60]:


# Посмотрим на описательные статистики групп по отдельности


# In[61]:


df.query('testgroup == "a"').describe().round(2)


# In[62]:


df.query('testgroup == "b"').describe()


# Показатель revenue (Std) в контрольной группы (а) значительно выше чем в тестовой (в)

# In[63]:


# Визуализируем распределение данных контрольной и тестовой группы


# In[64]:


fig, ax = plt.subplots(1,2, figsize=(15, 6))
sns.distplot(df.query('testgroup == "a"').revenue, kde=False, ax=ax[0], color = 'blue').set_title('Control')
sns.distplot(df.query('testgroup == "b"').revenue, kde=False, ax=ax[1], color = 'blue').set_title('Test')
plt.show()


# Вероятнее всего, что ситуация с высокой разницей revenue (Std) возникла из-за наличия ВИПов с высокими тратами 
# в контрольной группе

# In[65]:


# Выведем только данные по пользователям с произведенной оплатой


# In[66]:


df_pay = df.query('revenue > 0')

fig, ax = plt.subplots(1,2, figsize=(15, 6))
sns.distplot(df_pay.query('testgroup == "a"').revenue, kde=False, ax=ax[0], color = 'green').set_title('Control')
sns.distplot(df_pay.query('testgroup == "b"').revenue, kde=False, ax=ax[1], color = 'green').set_title('Test')
plt.show()


# Видим как расосредоточены данные в контрольной группе (подтверждаем наличие ВИПов)

# In[67]:


a = df_pay.query('testgroup == "a"').revenue.describe().round()
b = df_pay.query('testgroup == "b"').revenue.describe().round()
ab = pd.DataFrame(a).rename(columns={'revenue':'control'})
ab['test'] = b
ab


# In[68]:


# Выведем данные ВИПов (ограниение по сумме возьмем по максимальной границе тестовой группы)
# В идеале необходимо для каждой группы сформирвоать свой критерий оценки Випов


# In[69]:


df_vip = df.query('revenue > 4000')
df_vip.revenue.describe().round(2)


# In[70]:


# Посмотрим также на распределение платежеспособных пользователей контрольной группы с разбивками:


# In[71]:


fig, ax = plt.subplots(1,3, figsize=(20, 6))
sns.distplot(df_vip.revenue, kde=False, ax=ax[0], color = 'purple')   .set_title('Group A - VIP')
sns.distplot(df_pay.query('testgroup == "a"').query('revenue < 4000').revenue, kde=False, ax=ax[1], color = 'purple')   .set_title('Group A - w/o VIP')
sns.distplot(df_pay.query('testgroup == "b"').revenue, kde=False, ax=ax[2], color = 'purple').set_title('Test Group')
plt.show()


# In[72]:


# Построим сводную таблицу и добавим расчет метрик


# In[73]:


df_metr = df.groupby('testgroup', as_index=False)            .agg({'revenue':'sum','user_id':'nunique', 'pay_status':'sum'})            .rename(columns={'user_id':'n_users', 'pay_status':'pay_users'})

df_metr['CR'] = round(df_metr.pay_users / df_metr.n_users * 100, 2)
df_metr['ARPU'] = round(df_metr.revenue / df_metr.n_users, 2)
df_metr['ARPPU'] = round(df_metr.revenue / df_metr.pay_users, 2)
df_metr['VIP_share'] =  round(df_tops.revenue.sum() / df_metr.query('testgroup == "a"').revenue, 2)

df_metr


# В контрольной группе обнаружены ВИПы, что ставит под сомнение нормальное распредение групп.
# 
# 1. 123 ВИП игрока, что сотавляет около 6% от всей группы, принесли 89% выручки.
# 2. Конверсия у тестовой группы ниже на 0,06 процентных пунктов.
# 
# Перед тем как сделать выводы, проведем проверку через статистическую значимость получившихся различий в группах.
# Учитывая особенности данных, наиболее очевидными способами проверки являются U-критерий Манна-Уитни или Bootstrap.
# 
# Одним из условий применения критерия Манна-Уитни является то, что одинаковые значения в выборке должны быть сведены к минимуму (все числа должны быть разными), применить его в данном случае мы не можем, так как в текущих данных большую часть составляют именно схожие данные, поэтому будем использовать Bootstrap. 
# 
# Проверку произведем на ARPU. т.к. в описании задания он завялен как ключевой показатель.

# In[74]:


sample_1 = df[df.testgroup == "b"].revenue
sample_2 = df[df.testgroup == "a"].revenue


# In[75]:


# Создаем функцию
def get_bootstrap(
    data_column_1, # числовые значения первой выборки
    data_column_2, # числовые значения второй выборки
    boot_it = 1000,
    statistic = np.mean, # указываем интересующую нас статистику
    bootstrap_conf_level = 0.95
):
    boot_len = max([len(data_column_1), len(data_column_2)])
    boot_data = []
    for i in tqdm(range(boot_it)): # извлекаем подвыборки
        samples_1 = data_column_1.sample(
            boot_len, 
            replace = True # параметр возвращения
        ).values
        
        samples_2 = data_column_2.sample(
            boot_len, 
            replace = True
        ).values
        
        boot_data.append(statistic(samples_1-samples_2)) #применяем статистику
        
    pd_boot_data = pd.DataFrame(boot_data)
        
    left_quant = (1 - bootstrap_conf_level)/2
    right_quant = 1 - (1 - bootstrap_conf_level) / 2
    quants = pd_boot_data.quantile([left_quant, right_quant])
        
    p_1 = norm.cdf(
        x = 0, 
        loc = np.mean(boot_data), 
        scale = np.std(boot_data)
    )
    p_2 = norm.cdf(
        x = 0, 
        loc = -np.mean(boot_data), 
        scale = np.std(boot_data)
    )
    p_value = min(p_1, p_2) * 2
        
    # Визуализация
    _, _, bars = plt.hist(pd_boot_data[0], bins = 50)
    for bar in bars:
        if abs(bar.get_x()) <= quants.iloc[0][0] or abs(bar.get_x()) >= quants.iloc[1][0]:
            bar.set_facecolor('red')
        else: 
            bar.set_facecolor('blue')
            bar.set_edgecolor('black')
    
    plt.style.use('ggplot')
    plt.vlines(quants,ymin=0,ymax=50,linestyle='--')
    plt.xlabel('boot_data')
    plt.ylabel('frequency')
    plt.title("Histogram of boot_data")
    plt.show()
       
    return {"boot_data": boot_data, 
            "quants": quants, 
            "p_value": p_value}


# In[76]:


booted_data_ARPU = get_bootstrap(sample_1, sample_2)
HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))


# In[77]:


booted_data_ARPU["p_value"].round(2)


# In[78]:


booted_data_ARPU["quants"]


# P-value оказался больше 0.05, что не дает нам оснований отклонить нулевую гипотезу о равестве двух выборок.
# Статистически значимых различий между ARPU акций a и b не выявлено.
# 
# Перед проведением А/В теста в продукте было бы хорошо сделать проверку метрик с целью выявления чувствительности к изменениям (моделирование симуляция методом Монте Карло). Это позволит продуктам выбирать правильные, чувствительные метрики для эксперимента. Возможно, в текущем тесте, выбранные метрики не обладают нужной долей чувствительности чтобы заметить изменения в анализируемых группах.
# 
# С выявлением в группе Вип-игроков, было бы хорошо убедиться, что система сплитования трафика работает корректно, было бы полезно перед А/В тестом провести А/А тест. С целью проверки системы сплитования трафика на перекосы в распределениях/метриках/аудиторий, а частности позволило бы увидеть, что в какой-то группе присутсуют ВИП-игроки.

# 1. Добавить признаки: 
# видел ли пользователь предложение или нет; 
# кол-во сессий N игрока произошло; 
# признак пользовательского игрового события для нахождения связи с покупкой; 
# добавить признак старый / новый игрок; 
# частоту покупок игрока (кол-во транзакций).
# 2. Рассмотреть другие квази-метрики(близко связанные c выручкой), а не Revenue, так как возможно, метрика Revenue не так чувствительна к изменениям в продукте. 
# 3. Есть проблема сплитования трафика. Возможно, VIP пользователей в разработке сплитера, не учли из-за чего они попали в интерефес по умолчанию (Control).
# 4. Чистка данных, сравнить Test/Control без VIP игроков (формула поиска выбросов в Revenue, квантили (80-20)*3 = сумма выше которой выброс/VIP)
# 5. Сравнить 2 распределения Test/Control (без VIP) по выручке. Возможно игроков с N ср.чеком в N группе стало больше, несмотря на то, что в целом изменений - нет. Это важно, чтобы понимать сдивнули ли мы планку чека в сторону более "дешевой" аудитории или более платежеспособной.

# ## Задание 3
# 
# В игре Plants & Gardens каждый месяц проводятся тематические события, ограниченные по времени. В них игроки могут получить уникальные предметы для сада и персонажей, дополнительные монеты или бонусы. Для получения награды требуется пройти ряд уровней за определенное время. С помощью каких метрик можно оценить результаты последнего прошедшего события?
# Предположим, в другом событии мы усложнили механику событий так, что при каждой неудачной попытке выполнения уровня игрок будет откатываться на несколько уровней назад. Изменится ли набор метрик оценки результата? Если да, то как?
# 
# 1) Посчитать какое кол-во игроков приняли участие в ивенте (порог входа в задание min выполнили первые 2) от всех пользователей за N период.
# 
# 2) % выполнения игроками каждого задания в событии (насколько интересен пользователем был ивент).
# 
# 3) Распределение по игрокам и заданиям. Сегментирование пользователей 25-50-75-100%. Где 100% - кол-во игроков полностью выполнивших все задачи, 25% - прошел 25% от всех заданий и тд., лучше формировать данные по периодам, например, дням, чтобы исключить влияние откатов при проигрыше (применимо для 2 части задания).
# 
# 4) Признак пользователя новый/старый игрок (позволит отследить влияние события на разных типов игроков).
# 
# 5) Доп. разбивка по: а) тип устройстава ios / android (в дальнейшем на основании данных можно сделать А/В тест и посмотреть отклик игроков с разных платформ) б) города, для выделения N региона, в котором более лояльные пользователи.
# 
# 6) Посмотреть на пользователей, кто начал, но бросил выполнять после N этапа + распредление аналогичное п.3, по игрокам, на каком этапе, чаще всего "отваливаются", так мы поймем самое сложное задание, с которого игроки уходят.
# 
# 7) Доля пользователей, которые начали определенный уровень и "зафейлили", какой % пользователей возвращается в игру, а какой уходит. Так же на основании данных показателей, можно выявить на какой уровень возвращаются чаще, а с какого больше уходят и не возращаются.
# 
# 8) Пользуются ли игроки выпавшими из набора предметами.
# 
# 9) Кол-во пользователей заплативших за прохождение с распределением на этапы (на каком этапе произошла оплата).
# 
# 10) Увеличивается ли Retantion Rate. Стали ли чаще возвращатсья с запуском ивента. Как быстро показатель RR возвращается к обычному значению по приложению.
# 
# 11) Выросло ли ср. пользовательское время пребывания в приложении.
# 
# 12) Churn rate - показатель оттока: в целом и что произошло после старта события.
# 
# 13) Показатели: DAU (дневная аудитория, выросло ли кол-во игроков после коммуникации/пуш уведомлений о старте акции, и если, сохраняется на уровне выше чем "до акции", то можно судить об успешности акции) и MAU (месячная аудитория, данный показатель позволит оценить прирост аудитории в более длительной перспективе, например, сравнение приростов месяц к месяцу).
# 
# Технические детали:
# 14) Реалистично ли прохождение этапа в среднее время игровой сессии. Если да, то все хорошо, если нет, требуется пересмотр времени прохождения задания.
# 
# 
# 
# 
# 
# 
# 

# In[ ]:




